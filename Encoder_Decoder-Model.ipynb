{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ZV-AnOEa9KE"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J8o87Nd_JWk_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense,Flatten\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>processed_hindi</th>\n",
       "      <th>processed_english</th>\n",
       "      <th>len_processed_hindi</th>\n",
       "      <th>len_processed_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "      <td>वाह</td>\n",
       "      <td>wow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>बचाओ</td>\n",
       "      <td>help</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "      <td>उछलो</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>कूदो.</td>\n",
       "      <td>कूदो</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>छलांग.</td>\n",
       "      <td>छलांग</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   hindi processed_hindi processed_english  len_processed_hindi  \\\n",
       "0    Wow!    वाह!             वाह               wow                    1   \n",
       "1   Help!   बचाओ!            बचाओ              help                    1   \n",
       "2   Jump.   उछलो.            उछलो              jump                    1   \n",
       "3   Jump.   कूदो.            कूदो              jump                    1   \n",
       "4   Jump.  छलांग.           छलांग              jump                    1   \n",
       "\n",
       "   len_processed_english  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('new_processed_hindi_english.csv') \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['encoder_input'] ='<start>'+' '+train_df['processed_english']+' '+'<end>'\n",
    "train_df['decoder_input'] ='<start>'+' '+train_df['processed_hindi']+' '+'<end>'\n",
    "train_df['decoder_output'] = train_df['processed_hindi']+' '+'<end>'+' '+'<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13815, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>processed_hindi</th>\n",
       "      <th>processed_english</th>\n",
       "      <th>len_processed_hindi</th>\n",
       "      <th>len_processed_english</th>\n",
       "      <th>encoder_input</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "      <td>वाह</td>\n",
       "      <td>wow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;start&gt; wow &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; वाह &lt;end&gt;</td>\n",
       "      <td>वाह &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>बचाओ</td>\n",
       "      <td>help</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;start&gt; help &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; बचाओ &lt;end&gt;</td>\n",
       "      <td>बचाओ &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "      <td>उछलो</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;start&gt; jump &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; उछलो &lt;end&gt;</td>\n",
       "      <td>उछलो &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>कूदो.</td>\n",
       "      <td>कूदो</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;start&gt; jump &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; कूदो &lt;end&gt;</td>\n",
       "      <td>कूदो &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>छलांग.</td>\n",
       "      <td>छलांग</td>\n",
       "      <td>jump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;start&gt; jump &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; छलांग &lt;end&gt;</td>\n",
       "      <td>छलांग &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   hindi processed_hindi processed_english  len_processed_hindi  \\\n",
       "0    Wow!    वाह!             वाह               wow                    1   \n",
       "1   Help!   बचाओ!            बचाओ              help                    1   \n",
       "2   Jump.   उछलो.            उछलो              jump                    1   \n",
       "3   Jump.   कूदो.            कूदो              jump                    1   \n",
       "4   Jump.  छलांग.           छलांग              jump                    1   \n",
       "\n",
       "   len_processed_english       encoder_input        decoder_input  \\\n",
       "0                      1   <start> wow <end>    <start> वाह <end>   \n",
       "1                      1  <start> help <end>   <start> बचाओ <end>   \n",
       "2                      1  <start> jump <end>   <start> उछलो <end>   \n",
       "3                      1  <start> jump <end>   <start> कूदो <end>   \n",
       "4                      1  <start> jump <end>  <start> छलांग <end>   \n",
       "\n",
       "      decoder_output  \n",
       "0    वाह <end> <end>  \n",
       "1   बचाओ <end> <end>  \n",
       "2   उछलो <end> <end>  \n",
       "3   कूदो <end> <end>  \n",
       "4  छलांग <end> <end>  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_eng = int(np.percentile(train_df['len_processed_english'],95))+2\n",
    "max_len_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_hindi =int(np.percentile(train_df['len_processed_hindi'],95))+2\n",
    "max_len_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[train_df['len_processed_hindi']<=max_len_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13511, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[train_df['len_processed_english']<=max_len_hindi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13496, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english                  object\n",
       "hindi                    object\n",
       "processed_hindi          object\n",
       "processed_english        object\n",
       "len_processed_hindi       int64\n",
       "len_processed_english     int64\n",
       "encoder_input            object\n",
       "decoder_input            object\n",
       "decoder_output           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['encoder_input']=train_df.encoder_input.astype(str)\n",
    "train_df['decoder_input']=train_df.decoder_input.astype(str)\n",
    "train_df['decoder_output']=train_df.decoder_output.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train_df, test_size=0.15,random_state=42)\n",
    "# train, cv = train_test_split(train, test_size=1/9,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11471, 9), (2025, 9))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['encoder_input'].values)\n",
    "\n",
    "vocab_size_eng = len(tknizer_eng.word_index) + 1\n",
    "vocab_size_eng,max_len_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5672, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_hindi = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_hindi.fit_on_texts(train['decoder_input'].values)\n",
    "\n",
    "vocab_size_hindi = len(tknizer_hindi.word_index) + 1\n",
    "vocab_size_hindi,max_len_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.word_index['<start>'],tknizer_eng.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start>', '<end>')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.index_word[1],tknizer_eng.index_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e=tknizer_eng.texts_to_sequences(train['encoder_input'])\n",
    "X_train_h=tknizer_hindi.texts_to_sequences(train['decoder_input'])\n",
    "y_train_h=tknizer_hindi.texts_to_sequences(train['decoder_output'])\n",
    "\n",
    "X_test_e=tknizer_eng.texts_to_sequences(test['encoder_input'])\n",
    "X_test_h=tknizer_hindi.texts_to_sequences(test['decoder_input'])\n",
    "y_test_h=tknizer_hindi.texts_to_sequences(test['decoder_output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e=pad_sequences(X_train_e,maxlen=max_len_eng,padding='post')\n",
    "X_train_h=pad_sequences(X_train_h,maxlen=max_len_hindi,padding='post')\n",
    "y_train_h=pad_sequences(y_train_h,maxlen=max_len_hindi,padding='post')\n",
    "\n",
    "X_test_e=pad_sequences(X_test_e,maxlen=max_len_eng,padding='post')\n",
    "X_test_h=pad_sequences(X_test_h,maxlen=max_len_hindi,padding='post')\n",
    "y_test_h=pad_sequences(y_test_h,maxlen=max_len_hindi,padding='post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11471, 13), (11471, 14), (11471, 14), (2025, 13), (2025, 14), (2025, 14))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_e.shape,X_train_h.shape,y_train_h.shape,X_test_e.shape,X_test_h.shape,y_test_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11471, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,  211,    2, ...,    0,    0,    0],\n",
       "       [   1,   29,  298, ...,    0,    0,    0],\n",
       "       [   1,    5,  522, ..., 2728,    2,    0],\n",
       "       ...,\n",
       "       [   1,   10,    3, ...,    0,    0,    0],\n",
       "       [   1,   10,   21, ...,    0,    0,    0],\n",
       "       [   1,   45,   21, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_e.shape)\n",
    "X_train_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11471, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,  187,    2, ...,    0,    0,    0],\n",
       "       [   1,  178,   11, ...,    0,    0,    0],\n",
       "       [   1,  424,   28, ..., 1314,   54,    2],\n",
       "       ...,\n",
       "       [   1,    8,   66, ...,    0,    0,    0],\n",
       "       [   1,    8,   19, ...,    0,    0,    0],\n",
       "       [   1,   56,   22, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_h.shape)\n",
    "X_train_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 187,    2,    2, ...,    0,    0,    0],\n",
       "       [ 178,   11,   13, ...,    0,    0,    0],\n",
       "       [ 424,   28, 2279, ...,   54,    2,    2],\n",
       "       ...,\n",
       "       [   8,   66, 3403, ...,    0,    0,    0],\n",
       "       [   8,   19,  300, ...,    0,    0,    0],\n",
       "       [  56,   22,  253, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X_e,X_h,y_h,batch_size):\n",
    "    while True:\n",
    "        for i in range(0,X_e.shape[0]//batch_size):\n",
    "            encoder_input = X_e[i*batch_size:(i+1)*batch_size]\n",
    "            decoder_input = X_h[i*batch_size:(i+1)*batch_size]\n",
    "            decoder_output_= y_h[i*batch_size:(i+1)*batch_size]\n",
    "            decoder_output=np.zeros((batch_size,max_len_hindi,vocab_size_hindi))\n",
    "            for i in range(batch_size):\n",
    "                for j in range(max_len_hindi):\n",
    "                    k=decoder_output_[i][j]\n",
    "                    decoder_output[i][j][k]=1\n",
    "            yield([encoder_input, decoder_input], decoder_output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,verbose=1,mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'val_loss': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "            \n",
    "history_own=LossHistory()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def changeLearningRate(epoch,lr):\n",
    "    if len(history_own.history['val_loss'])>1: #check if there there two elements   \n",
    "        if(history_own.history['val_loss'][-1] > history_own.history['val_loss'][-2]): \n",
    "            return(lr-(0.1*lr))\n",
    "    if ((epoch+1)%10)==0 and epoch!=0:\n",
    "        return(lr-(0.05*lr))\n",
    "    else:\n",
    "        return lr\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [history_own,earlystop,lrschedule] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=100\n",
    "lstm_units=100\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input :  (?, ?)\n",
      "Encoder after embedding layer :  (?, ?, 100)\n",
      "Encoder output after lstm :  (?, 100)\n",
      "Encoder state_h after lstm :  (?, 100)\n",
      "Encoder state_c after lstm :  (?, 100)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "print('Encoder input : ',encoder_inputs.shape)\n",
    "enc_emb =  Embedding(vocab_size_eng,embedding_dim)(encoder_inputs)\n",
    "print('Encoder after embedding layer : ',enc_emb.shape)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "print('Encoder output after lstm : ',encoder_outputs.shape)\n",
    "print('Encoder state_h after lstm : ',state_h.shape)\n",
    "print('Encoder state_c after lstm : ',state_c.shape)\n",
    "print('-'*40)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder inputs :  (?, ?)\n",
      "Decoder after embedding layer :  (?, ?, 100)\n",
      "Decoder outputs after lstm :  (?, ?, 100)\n",
      "Decoder outputs after dense layer :  (?, ?, 5672)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "print('Decoder inputs : ',decoder_inputs.shape)\n",
    "dec_emb_layer = Embedding(vocab_size_hindi,embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "print('Decoder after embedding layer : ',dec_emb.shape)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)\n",
    "print('Decoder outputs after lstm : ',decoder_outputs.shape)\n",
    "decoder_dense = Dense(vocab_size_hindi, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "print('Decoder outputs after dense layer : ',decoder_outputs.shape)\n",
    "print('-'*40)\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop=optimizers.rmsprop()\n",
    "model.compile(optimizer=rmsprop, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    417700      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    567200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100), (None, 80400       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 100),  80400       embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5672)   572872      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,718,572\n",
      "Trainable params: 1,718,572\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(retina=True, filename='train_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train_e)\n",
    "val_samples = len(X_test_e)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ILIYAS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ILIYAS\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 59s 328ms/step - loss: 3.5818 - val_loss: 2.7537\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 58s 321ms/step - loss: 2.7671 - val_loss: 2.5858\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 59s 328ms/step - loss: 2.6172 - val_loss: 2.4839\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 2.5075 - val_loss: 2.3975\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 2.4202 - val_loss: 2.3086\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 60s 338ms/step - loss: 2.3363 - val_loss: 2.2261\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 2.2518 - val_loss: 2.1710\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 2.1722 - val_loss: 2.1039\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "179/179 [==============================] - 62s 346ms/step - loss: 2.0990 - val_loss: 2.0626\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "179/179 [==============================] - 62s 349ms/step - loss: 2.0295 - val_loss: 2.0175\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 62s 345ms/step - loss: 1.9692 - val_loss: 1.9730\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 63s 350ms/step - loss: 1.9136 - val_loss: 1.9418\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 63s 351ms/step - loss: 1.8610 - val_loss: 1.9143\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 62s 347ms/step - loss: 1.8108 - val_loss: 1.8768\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 63s 350ms/step - loss: 1.7623 - val_loss: 1.8599\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 61s 343ms/step - loss: 1.7164 - val_loss: 1.8353\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 60s 338ms/step - loss: 1.6708 - val_loss: 1.7982\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 1.6275 - val_loss: 1.7768\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0009500000160187483.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 1.5858 - val_loss: 1.7494\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 1.5429 - val_loss: 1.7232\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 1.5053 - val_loss: 1.7105\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 1.4692 - val_loss: 1.6722\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 1.4351 - val_loss: 1.6562\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 1.4016 - val_loss: 1.6286\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 60s 338ms/step - loss: 1.3690 - val_loss: 1.6111\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 60s 335ms/step - loss: 1.3379 - val_loss: 1.5877\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 60s 338ms/step - loss: 1.3073 - val_loss: 1.5678\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 1.2782 - val_loss: 1.5527\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0009025000035762787.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 1.2487 - val_loss: 1.5413\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0008573750033974648.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 1.2200 - val_loss: 1.5081\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 1.1928 - val_loss: 1.4881\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 1.1687 - val_loss: 1.4835\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 1.1447 - val_loss: 1.4606\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 1.1212 - val_loss: 1.4460\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 1.0990 - val_loss: 1.4246\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 1.0770 - val_loss: 1.4101\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 1.0564 - val_loss: 1.3967\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0008573749801144004.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 1.0345 - val_loss: 1.3982\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007716374821029603.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 1.0089 - val_loss: 1.3850\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007330556079978123.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 0.9852 - val_loss: 1.3815\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 0.9673 - val_loss: 1.3745\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.9504 - val_loss: 1.3743\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 60s 335ms/step - loss: 0.9336 - val_loss: 1.3601\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.9168 - val_loss: 1.3587\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 60s 335ms/step - loss: 0.9019 - val_loss: 1.3361\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0007330555818043649.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.8863 - val_loss: 1.3482\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006597500236239284.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 0.8668 - val_loss: 1.3180\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006597500178031623.\n",
      "179/179 [==============================] - 60s 335ms/step - loss: 0.8516 - val_loss: 1.3238\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0005937750160228461.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.8345 - val_loss: 1.3149\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.000564086259691976.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 0.8195 - val_loss: 1.3019\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0005640862509608269.\n",
      "179/179 [==============================] - 60s 335ms/step - loss: 0.8079 - val_loss: 1.3020\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0005076776258647441.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 0.7936 - val_loss: 1.2980\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.000507677614223212.\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 0.7820 - val_loss: 1.2899\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.000507677614223212.\n",
      "179/179 [==============================] - 61s 338ms/step - loss: 0.7723 - val_loss: 1.2830\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.000507677614223212.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.7626 - val_loss: 1.2753\n",
      "Epoch 56/200\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.000507677614223212.\n",
      "179/179 [==============================] - 60s 337ms/step - loss: 0.7534 - val_loss: 1.2827\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0004569098528008908.\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 0.7411 - val_loss: 1.2725\n",
      "Epoch 58/200\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0004569098528008908.\n",
      "179/179 [==============================] - 64s 359ms/step - loss: 0.7318 - val_loss: 1.2708\n",
      "Epoch 59/200\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0004569098528008908.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.7237 - val_loss: 1.2633\n",
      "Epoch 60/200\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00043406436016084625.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.7148 - val_loss: 1.2555\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.00043406436452642083.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.7066 - val_loss: 1.2621\n",
      "Epoch 62/200\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0003906579280737787.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.6970 - val_loss: 1.2502\n",
      "Epoch 63/200\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00039065792225301266.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.6892 - val_loss: 1.2524\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0003515921300277114.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 0.6804 - val_loss: 1.2411\n",
      "Epoch 65/200\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0003515921416692436.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.6737 - val_loss: 1.2501\n",
      "Epoch 66/200\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0003164329275023192.\n",
      "179/179 [==============================] - 62s 345ms/step - loss: 0.6665 - val_loss: 1.2496\n",
      "Epoch 67/200\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0003164329391438514.\n",
      "179/179 [==============================] - 67s 373ms/step - loss: 0.6599 - val_loss: 1.2416\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0003164329391438514.\n",
      "179/179 [==============================] - 64s 358ms/step - loss: 0.6553 - val_loss: 1.2443\n",
      "Epoch 69/200\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00028478964522946624.\n",
      "179/179 [==============================] - 65s 362ms/step - loss: 0.6484 - val_loss: 1.2411\n",
      "Epoch 70/200\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0002705501712625846.\n",
      "179/179 [==============================] - 62s 347ms/step - loss: 0.6424 - val_loss: 1.2411\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.00024349515151698143.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.6365 - val_loss: 1.2418\n",
      "Epoch 72/200\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0002191456311265938.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.6309 - val_loss: 1.2360\n",
      "Epoch 73/200\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00021914562967140228.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.6266 - val_loss: 1.2371\n",
      "Epoch 74/200\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00019723106670426204.\n",
      "179/179 [==============================] - 61s 342ms/step - loss: 0.6223 - val_loss: 1.2367\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.00019723107106983662.\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 0.6185 - val_loss: 1.2345\n",
      "Epoch 76/200\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.00019723107106983662.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.6153 - val_loss: 1.2346\n",
      "Epoch 77/200\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.00017750796396285296.\n",
      "179/179 [==============================] - 62s 347ms/step - loss: 0.6113 - val_loss: 1.2347\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.00015975716232787817.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.6072 - val_loss: 1.2311\n",
      "Epoch 79/200\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.00015975716814864427.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 0.6043 - val_loss: 1.2334\n",
      "Epoch 80/200\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.00014378145133377984.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 0.6011 - val_loss: 1.2281\n",
      "Epoch 81/200\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.00014378144987858832.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.5984 - val_loss: 1.2314\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001294033048907295.\n",
      "179/179 [==============================] - 62s 345ms/step - loss: 0.5956 - val_loss: 1.2268\n",
      "Epoch 83/200\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001294032990699634.\n",
      "179/179 [==============================] - 62s 346ms/step - loss: 0.5932 - val_loss: 1.2309\n",
      "Epoch 84/200\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.00011646296916296705.\n",
      "179/179 [==============================] - 61s 339ms/step - loss: 0.5907 - val_loss: 1.2258\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0001164629720733501.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 0.5885 - val_loss: 1.2298\n",
      "Epoch 86/200\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.00010481667486601509.\n",
      "179/179 [==============================] - 61s 342ms/step - loss: 0.5862 - val_loss: 1.2246\n",
      "Epoch 87/200\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.00010481667413841933.\n",
      "179/179 [==============================] - 62s 345ms/step - loss: 0.5844 - val_loss: 1.2284\n",
      "Epoch 88/200\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 9.43350067245774e-05.\n",
      "179/179 [==============================] - 60s 338ms/step - loss: 0.5823 - val_loss: 1.2232\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 9.433500963496044e-05.\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.5806 - val_loss: 1.2272\n",
      "Epoch 90/200\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 8.49015086714644e-05.\n",
      "179/179 [==============================] - 62s 345ms/step - loss: 0.5788 - val_loss: 1.2236\n",
      "Epoch 91/200\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 8.490150503348559e-05.\n",
      "179/179 [==============================] - 60s 337ms/step - loss: 0.5773 - val_loss: 1.2258\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 7.641135453013703e-05.\n",
      "179/179 [==============================] - 61s 342ms/step - loss: 0.5756 - val_loss: 1.2232\n",
      "Epoch 93/200\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 7.641135744052008e-05.\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 0.5743 - val_loss: 1.2250\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00093: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28041ff1f60>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train_e,X_train_h,y_train_h, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test_e,X_test_h,y_test_h, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('nmt_weights_20e1-new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('nmt_weights_20e1-new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_own.history['loss'], 'r')\n",
    "plt.plot(history_own.history['val_loss'], 'b')\n",
    "plt.legend({'Train loss': 'r', 'Validation loss':'b'})\n",
    "plt.ylabel('logloss')\n",
    "plt.xlabel('number of epoch')\n",
    "plt.title('Logloss vs epoch plot')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    " \n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = tknizer_hindi.word_index['<start>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tknizer_hindi.index_word[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<end>'):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_text(x,dictionary):\n",
    "    s=''\n",
    "    for i in x[0]:\n",
    "        if i==0:\n",
    "            break\n",
    "        if dictionary[i]=='<end>' or dictionary[i]=='<start>':\n",
    "            continue\n",
    "        s+=dictionary[i]+' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1='चाहो तो तुम जा सकती हो'\n",
    "s2='चाहो तो तुम जा सकती हो <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sentence_bleu([s1.split()],s2.replace('<end>','').split())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train_e,X_train_h,y_train_h, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  really \n",
      "Actual Hindi Translation:  सच \n",
      "Predicted Hindi Translation:  सच <end>\n",
      "BLEU Score :  1.821831989445342e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  we tried to save tom \n",
      "Actual Hindi Translation:  हमने टॉम को बचाने की कोशिश की \n",
      "Predicted Hindi Translation:  टॉम को तुम्हें पता पड़ेगी <end>\n",
      "BLEU Score :  5.6228231334895985e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  the police tried hard to unravel the mystery of killing \n",
      "Actual Hindi Translation:  पुलिस ने हत्या की गुथी को सुलझाने के लिए कड़ा प्रयास किया \n",
      "Predicted Hindi Translation:  पुलिस ने पुलिस को किसी को साल कर दिया कि तुमने ठीक से दिया था <end>\n",
      "BLEU Score :  5.157006819435075e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  do you have brothers and sisters \n",
      "Actual Hindi Translation:  तुम्हारे पास भाई बहन हैं क्या \n",
      "Predicted Hindi Translation:  तुम्हारे पास भाई बहन हैं क्या <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  your room is ready \n",
      "Actual Hindi Translation:  आपका कमरा तैयार है \n",
      "Predicted Hindi Translation:  आपका कमरा तैयार है <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  have you seen tom today no i have not \n",
      "Actual Hindi Translation:  आज टॉम को देखा नहीं नहीं देखा \n",
      "Predicted Hindi Translation:  आज टॉम को देखा नहीं नहीं देखा <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  do as tom says \n",
      "Actual Hindi Translation:  टॉम जैसा कहे वैसा कीजिए \n",
      "Predicted Hindi Translation:  टॉम जैसा कहे वैसा करो <end>\n",
      "BLEU Score :  0.668740304976422\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he prefers french to german \n",
      "Actual Hindi Translation:  उसे फ़्रानसीसी जर्मन से ज़्यादा अच्छी लगती है \n",
      "Predicted Hindi Translation:  वह शहर में शहर करना चाहती क्यों नहीं <end>\n",
      "BLEU Score :  0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  it is no use crying over spilt milk \n",
      "Actual Hindi Translation:  अब पछताए क्या होत जब चिड़िया चुग गई खेत \n",
      "Predicted Hindi Translation:  उसके क्या चाहिए <end>\n",
      "BLEU Score :  1.8734367966736672e-232\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  i do a lot of things \n",
      "Actual Hindi Translation:  मैं बहुत सारे चीज़ें करता हूँ \n",
      "Predicted Hindi Translation:  मैं बहुत सारे <end>\n",
      "BLEU Score :  4.493053873107152e-78\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  i am going to go to america next year \n",
      "Actual Hindi Translation:  अगले साल मैं अमरीका जाने वाला हूँ \n",
      "Predicted Hindi Translation:  मैं अगले हफ़्ते से बारे में बहुत रहा हूँ <end>\n",
      "BLEU Score :  1.384292958842266e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  a good idea suddenly struck her \n",
      "Actual Hindi Translation:  अचानक उसे एक अच्छा आइडिया आया \n",
      "Predicted Hindi Translation:  अचानक उसे एक अच्छा लगता है <end>\n",
      "BLEU Score :  0.5081327481546147\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  what kind of people do you like best \n",
      "Actual Hindi Translation:  आपको किस तरह के लोग सबसे ज़्यादा पसंद हैं \n",
      "Predicted Hindi Translation:  तुम्हारे पास जर्मनी में समय क्या है <end>\n",
      "BLEU Score :  0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he cut the envelope open \n",
      "Actual Hindi Translation:  उसने लिफ़ाफ़े को काटकर खोल दिया \n",
      "Predicted Hindi Translation:  उसने पैसों की कमी थी <end>\n",
      "BLEU Score :  9.97486269044271e-232\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  if you wish you can go \n",
      "Actual Hindi Translation:  चाहो तो तुम जा सकती हो \n",
      "Predicted Hindi Translation:  चाहो तो तुम जा सकती हो <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  say goodbye \n",
      "Actual Hindi Translation:  अलविदा कहिए \n",
      "Predicted Hindi Translation:  पार्टी गई <end>\n",
      "BLEU Score :  0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  what do you know about germany \n",
      "Actual Hindi Translation:  आपको जर्मनी के बारे में क्या मालूम है \n",
      "Predicted Hindi Translation:  तुम जर्मनी के बारे में क्या जानते हो <end>\n",
      "BLEU Score :  0.5169731539571706\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he knocked at the door \n",
      "Actual Hindi Translation:  उसने दरवाज़े पर खटखटाया \n",
      "Predicted Hindi Translation:  उसने दरवाज़े पर खटखटाया <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  may we accompany you on your walk \n",
      "Actual Hindi Translation:  हम तुम्हारे साथ सैर करने चलें क्या \n",
      "Predicted Hindi Translation:  हम तुम्हारे साथ सैर करने चलें क्या <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  why did you come here this morning \n",
      "Actual Hindi Translation:  तुम आज सुबह यहाँ क्यों आए \n",
      "Predicted Hindi Translation:  तुम यहाँ क्यों भी क्यों आए हो <end>\n",
      "BLEU Score :  9.85444998995587e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he made up an excuse \n",
      "Actual Hindi Translation:  उसने कोई बहाना बना लिया \n",
      "Predicted Hindi Translation:  उसने कोई बहाना बना लिया <end>\n",
      "BLEU Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  somebody is watching us \n",
      "Actual Hindi Translation:  किसी की हम पर नज़र है \n",
      "Predicted Hindi Translation:  कोई हमारे साथ आ रहा है <end>\n",
      "BLEU Score :  1.1640469867513693e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  the novel is very exciting \n",
      "Actual Hindi Translation:  यह उपन्यास बहुत रोमांचक है \n",
      "Predicted Hindi Translation:  यह उपन्यास बहुत है <end>\n",
      "BLEU Score :  7.227401369829121e-78\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = generate_batch(X_test_e,X_test_h,y_test_h, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he seems to know us \n",
      "Actual Hindi Translation:  लगता है वह हमें जानता है \n",
      "Predicted Hindi Translation:  वह हमें पता है <end>\n",
      "BLEU Score :  6.397495320955232e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  you have got to stop tom \n",
      "Actual Hindi Translation:  तुम्हे टॉम को रोकना ही होगा \n",
      "Predicted Hindi Translation:  तुम ने टॉम को हमारी मदद करना सबसे सहायक उससे लिए <end>\n",
      "BLEU Score :  5.477489369001354e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  what do you want me to do \n",
      "Actual Hindi Translation:  तुम मुझसे क्या करवाना चाहते हो \n",
      "Predicted Hindi Translation:  क्या तुम मुझसे करना चाहते हो <end>\n",
      "BLEU Score :  1.133422688662942e-154\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  the policeman the man open the door \n",
      "Actual Hindi Translation:  ने आदमी को दरवाज़ा खोलते देखा \n",
      "Predicted Hindi Translation:  यह आदमी की जहाज़ ने उसे साल किया गया <end>\n",
      "BLEU Score :  1.2508498911928379e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  he lived there all by himself \n",
      "Actual Hindi Translation:  वह वहां अकेले से रहा \n",
      "Predicted Hindi Translation:  वे सब से लिए पड़ोस <end>\n",
      "BLEU Score :  1.2183324802375697e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  she is busy at present and can not speak to you \n",
      "Actual Hindi Translation:  वे अभी व्यस्थ हैं और आपसे बात नहीं कर सकतीं हैं \n",
      "Predicted Hindi Translation:  वे अभी तक आपको संगीत लिख रहा है <end>\n",
      "BLEU Score :  4.4567910894251624e-155\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  we should love our neighbors \n",
      "Actual Hindi Translation:  हमे पड़ोसियों के साथ प्रेमपूर्वक रहना चहिए \n",
      "Predicted Hindi Translation:  हमें उसके साथ करना चाहिए ने <end>\n",
      "BLEU Score :  9.853445011990208e-232\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  the animals in the forest died off \n",
      "Actual Hindi Translation:  जंगल के जानवर मर गए \n",
      "Predicted Hindi Translation:  ट्रेन अचानक जा रही थी <end>\n",
      "BLEU Score :  0\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence:  you must not be afraid of making mistakes when learning a language \n",
      "Actual Hindi Translation:  कोई भी नई भाषा सीखने में ग़लतियों से डरना नहीं चहिए \n",
      "Predicted Hindi Translation:  तुम्हे थोड़ा जाने से दस के पीछे का नहीं बोलना चाहिए <end>\n",
      "BLEU Score :  1.1896457329133973e-231\n"
     ]
    }
   ],
   "source": [
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence: ',index_to_text(input_seq,tknizer_eng.index_word))\n",
    "print('Actual Hindi Translation: ',index_to_text(actual_output,tknizer_hindi.index_word))\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "score = sentence_bleu([index_to_text(actual_output,tknizer_hindi.index_word).split()],decoded_sentence.replace('<end>','').split())\n",
    "print('BLEU Score : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of All_ML_codes1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
